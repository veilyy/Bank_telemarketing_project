# –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫

import numpy as np
import pandas as pd
import joblib
import json
import os
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from src.preprocessing import Preprocessor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

def main():
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv('data/bank-additional-full.csv', sep=';')
    
    # 2. –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ X –∏ y
    df['y'] = df['y'].map({'yes': 1, 'no': 0})
    X = df.drop('y', axis=1)
    y = df['y']

    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

    print(f"–í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {X.shape[0]} —Å—Ç—Ä–æ–∫, {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print(f"–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {y.sum()} 'yes' ({y.mean():.2%})")
    
    # 3. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
    print("\n" + "="*50)
    print("ü§ñ –í–´–ë–ï–†–ò–¢–ï –ú–û–î–ï–õ–¨ –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø:")
    print("="*50)
    print("1. XGBoost (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã) - –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø")
    print("2. Random Forest")
    print("3. Logistic Regression")
    print("4. XGBoost (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
    print("="*50)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    choice = input()
    
    print("\n" + "="*50)
    answer = input("–£–±—Ä–∞—Ç—å –∏–∑ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫ Duration? (–¥–∞/–Ω–µ—Ç): ").lower().strip()
    print("\n" + "="*50)

    if answer in ['–¥–∞', '–¥', 'yes', 'y']:
        duration = False

    elif answer in ['–Ω–µ—Ç', '–Ω', 'no', 'n']:
        duration = True

    else:
        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ '–¥–∞' –∏–ª–∏ '–Ω–µ—Ç'")

    # 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±–æ—Ä–∞
    if choice == '1':  # XGBoost –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
        model_class = XGBClassifier
        model_name = "xgboost"
        model_params = {'n_estimators': 232,
                        'max_depth': 8,
                        'learning_rate': 0.01454877020944003,
                        'subsample': 0.9955153022026433,
                        'colsample_bytree': 0.9679592682343201,
                        'min_child_weight': 7,
                        'gamma': 0.34955546586648234,
                        'reg_alpha': 1.1082729972353083e-08,
                        'reg_lambda': 5.343890477972791e-07,
                         'scale_pos_weight': 2.773973433925954}
        optimal_threshold = 0.34
        
    elif choice == '2':  # Random Forest
        model_class = RandomForestClassifier
        model_name = "random_forest"
        model_params = {
            'n_estimators': 200,
            'max_depth': 15,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'class_weight': 'balanced',
            'random_state': 42,
            'n_jobs': -1
        }
        optimal_threshold = 0.5

        
    elif choice == '3':  # Logistic Regression
        model_class = LogisticRegression
        model_name = "logistic_regression"
        model_params = {
            'C': 0.1,
            'class_weight': 'balanced',
            'max_iter': 1000,
            'random_state': 42,
            'solver': 'liblinear'
        }
        optimal_threshold = 0.67

    else:  # XGBoost –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 
        model_class = XGBClassifier
        model_name = "xgboost_default"
        model_params = {
            'n_estimators': 100,
            'max_depth': 5,
            'learning_rate': 0.1,
            'scale_pos_weight': len(y[y==0]) / len(y[y==1]),
            'random_state': 42
        }
        optimal_threshold = 0.6
    
    print(f"\n‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
    
    # 5. –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –Ω–µ—Ç
    os.makedirs('models/preprocessor', exist_ok=True)   
    os.makedirs('models/metrics', exist_ok=True)       
    
    # 6 C–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä 
    if duration:
        preproc = Preprocessor(duration = True)

    else:
        preproc = Preprocessor(duration= False)
    
    X_train = preproc.fit_transform(X_train)
    X_test = preproc.transform(X_test)

    # 7 –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = model_class(**model_params)
    model.fit(X_train, y_train)

    # 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ –æ–±—â—É—é –ø–∞–ø–∫—É preprocessor
    import joblib
    preproc.save('models/preprocessor/')
    print('–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ models/preprocessor')
    # 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ –∫–æ—Ä–µ–Ω—å models

    joblib.dump(model, f'models/{model_name}.pkl')
    print("–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models")
    
    # 10. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–∏–∫—Ç –º–æ–¥–µ–ª–∏
    y_pred = model.predict_proba(X_test)[:, 1]
    y_pred_thresholded = (y_pred >= optimal_threshold).astype(int)

    # 10.1 –ú–µ—Ç—Ä–∏–∫–∏
    metrics = {}
    metrics['f1'] = f1_score(y_test, y_pred_thresholded)
    metrics['precision'] = precision_score(y_test, y_pred_thresholded)
    metrics['recall'] = recall_score(y_test, y_pred_thresholded)
    metrics['roc_auc'] = roc_auc_score(y_test, y_pred)
    metrics['threshold'] = optimal_threshold


    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    os.makedirs('models/metrics', exist_ok=True)
    with open('models/metrics/latest_metrics.json', 'w') as f:
        json.dump(metrics, f, indent=4)
    
        print(" –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ models/metrics/")
    
    # 11. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    params_to_save = {
        'model_name': model_name,
        'model_params': model_params,
        'threshold': optimal_threshold,
    }
    
    with open('models/model_params.json', 'w') as f:
        json.dump(params_to_save, f, indent=4)
    print(" –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ models/model_params.json")
    
    # 12. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # –°–æ–∑–¥–∞–µ–º DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    importance_df = pd.DataFrame({
            'feature': model.feature_names_in_,
            'importance': model.feature_importances_}).sort_values('importance', ascending=False)

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
    os.makedirs('models/metrics', exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    importance_df.to_csv(  
        f'models/metrics/feature_importance_{model_name}.csv', index=False)

    print(f"Feature importance —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ models/metrics/feature_importance_{model_name}.csv")
    print(f" –¢–æ–ø-5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    print(importance_df.head())

    # 13. –ò—Ç–æ–≥
    print("\n" + "="*50)
    print(f" –ú–æ–¥–µ–ª—å: {model_name}")
    print(f"F1-score: {metrics['f1']:.4f}")
    print(f"ROC-AUC:  {metrics['roc_auc']:.4f}")
    print(f"Precision: {metrics['precision']:.4f}")
    print(f"Recall: {metrics['recall']:.4f}")
    print(f"Threshold: {optimal_threshold:.4f}")
    print("="*50)

if __name__ == "__main__":
    main()